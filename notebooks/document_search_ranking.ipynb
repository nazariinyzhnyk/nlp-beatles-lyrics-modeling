{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nazariinyzhnyk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nazariinyzhnyk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import WordEmbeddingSimilarityIndex\n",
    "from gensim.similarities import SparseTermSimilarityMatrix\n",
    "from gensim.similarities import SoftCosineSimilarity\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from preprocessing import get_dataframe, set_seed\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AHardDaysNight</td>\n",
       "      <td>Ill_Be_Back.txt</td>\n",
       "      <td>You know, if you break my heart I'll go But I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AHardDaysNight</td>\n",
       "      <td>Cant_Buy_Me_Love.txt</td>\n",
       "      <td>Can't buy me love, oh Love, oh Can't buy me lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AHardDaysNight</td>\n",
       "      <td>Any_Time_At_All.txt</td>\n",
       "      <td>Any time at all Any time at all Any time at al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AHardDaysNight</td>\n",
       "      <td>A_Hard_Days_Night.txt</td>\n",
       "      <td>It's been a hard day's night And I've been wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AHardDaysNight</td>\n",
       "      <td>Ill_Cry_Instead.txt</td>\n",
       "      <td>I've got every reason on earth to be mad 'Caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>Help</td>\n",
       "      <td>Another_Girl.txt</td>\n",
       "      <td>For I have got another girl Another girl  You'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>Help</td>\n",
       "      <td>Help.txt</td>\n",
       "      <td>Help! I need somebody Help! Not just anybody H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>Help</td>\n",
       "      <td>Ive_Just_Seen_A_Face.txt</td>\n",
       "      <td>I've just seen a face I can't forget the time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>Help</td>\n",
       "      <td>Tell_Me_What_You_See.txt</td>\n",
       "      <td>If you let me take your heart I will prove to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>Help</td>\n",
       "      <td>Its_Only_Love.txt</td>\n",
       "      <td>I get high when I see you go by My, oh my When...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              album                      song  \\\n",
       "0    AHardDaysNight           Ill_Be_Back.txt   \n",
       "1    AHardDaysNight      Cant_Buy_Me_Love.txt   \n",
       "2    AHardDaysNight       Any_Time_At_All.txt   \n",
       "3    AHardDaysNight     A_Hard_Days_Night.txt   \n",
       "4    AHardDaysNight       Ill_Cry_Instead.txt   \n",
       "..              ...                       ...   \n",
       "177            Help          Another_Girl.txt   \n",
       "178            Help                  Help.txt   \n",
       "179            Help  Ive_Just_Seen_A_Face.txt   \n",
       "180            Help  Tell_Me_What_You_See.txt   \n",
       "181            Help         Its_Only_Love.txt   \n",
       "\n",
       "                                                  text  \n",
       "0    You know, if you break my heart I'll go But I'...  \n",
       "1    Can't buy me love, oh Love, oh Can't buy me lo...  \n",
       "2    Any time at all Any time at all Any time at al...  \n",
       "3    It's been a hard day's night And I've been wor...  \n",
       "4    I've got every reason on earth to be mad 'Caus...  \n",
       "..                                                 ...  \n",
       "177  For I have got another girl Another girl  You'...  \n",
       "178  Help! I need somebody Help! Not just anybody H...  \n",
       "179  I've just seen a face I can't forget the time ...  \n",
       "180  If you let me take your heart I will prove to ...  \n",
       "181  I get high when I see you go by My, oh my When...  \n",
       "\n",
       "[182 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_dataframe(os.path.join('..', 'data', 'lyrics'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicated songs from df - see basic_EDA.ipynb for detailed description\n",
    "df.drop(df[(df.song == \"All_You_Need_Is_Love.txt\") & (df.album == \"YellowSubmarine\")].index, inplace=True)\n",
    "df.drop(df[(df.song == \"Yellow_Submarine.txt\") & (df.album == \"YellowSubmarine\")].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AHardDaysNight</td>\n",
       "      <td>Ill_Be_Back.txt</td>\n",
       "      <td>You know, if you break my heart I'll go But I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AHardDaysNight</td>\n",
       "      <td>Cant_Buy_Me_Love.txt</td>\n",
       "      <td>Can't buy me love, oh Love, oh Can't buy me lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AHardDaysNight</td>\n",
       "      <td>Any_Time_At_All.txt</td>\n",
       "      <td>Any time at all Any time at all Any time at al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AHardDaysNight</td>\n",
       "      <td>A_Hard_Days_Night.txt</td>\n",
       "      <td>It's been a hard day's night And I've been wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AHardDaysNight</td>\n",
       "      <td>Ill_Cry_Instead.txt</td>\n",
       "      <td>I've got every reason on earth to be mad 'Caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>Help</td>\n",
       "      <td>Another_Girl.txt</td>\n",
       "      <td>For I have got another girl Another girl  You'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>Help</td>\n",
       "      <td>Help.txt</td>\n",
       "      <td>Help! I need somebody Help! Not just anybody H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>Help</td>\n",
       "      <td>Ive_Just_Seen_A_Face.txt</td>\n",
       "      <td>I've just seen a face I can't forget the time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>Help</td>\n",
       "      <td>Tell_Me_What_You_See.txt</td>\n",
       "      <td>If you let me take your heart I will prove to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>Help</td>\n",
       "      <td>Its_Only_Love.txt</td>\n",
       "      <td>I get high when I see you go by My, oh my When...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              album                      song  \\\n",
       "0    AHardDaysNight           Ill_Be_Back.txt   \n",
       "1    AHardDaysNight      Cant_Buy_Me_Love.txt   \n",
       "2    AHardDaysNight       Any_Time_At_All.txt   \n",
       "3    AHardDaysNight     A_Hard_Days_Night.txt   \n",
       "4    AHardDaysNight       Ill_Cry_Instead.txt   \n",
       "..              ...                       ...   \n",
       "177            Help          Another_Girl.txt   \n",
       "178            Help                  Help.txt   \n",
       "179            Help  Ive_Just_Seen_A_Face.txt   \n",
       "180            Help  Tell_Me_What_You_See.txt   \n",
       "181            Help         Its_Only_Love.txt   \n",
       "\n",
       "                                                  text  \n",
       "0    You know, if you break my heart I'll go But I'...  \n",
       "1    Can't buy me love, oh Love, oh Can't buy me lo...  \n",
       "2    Any time at all Any time at all Any time at al...  \n",
       "3    It's been a hard day's night And I've been wor...  \n",
       "4    I've got every reason on earth to be mad 'Caus...  \n",
       "..                                                 ...  \n",
       "177  For I have got another girl Another girl  You'...  \n",
       "178  Help! I need somebody Help! Not just anybody H...  \n",
       "179  I've just seen a face I can't forget the time ...  \n",
       "180  If you let me take your heart I will prove to ...  \n",
       "181  I get high when I see you go by My, oh my When...  \n",
       "\n",
       "[180 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 0 (dummy): tf-idf on unprocessed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = 'all is love'\n",
    "documents = list(df.text)\n",
    "\n",
    "doc_vectors = TfidfVectorizer().fit_transform([search_terms] + documents)\n",
    "\n",
    "cosine_similarities = cosine_similarity(doc_vectors[0:1], doc_vectors).flatten()\n",
    "document_scores = [item.item() for item in cosine_similarities[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2407 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 stored elements: 'all' 'is' 'love' in the scope of one vector are compared to all the rest vectors\n",
    "# with cosine similarity metric. This metric demonstrates how far are vectors from each other.\n",
    "# So, if we compare query to all of our documents, transformed in the same way (vectorized with tf-idf)\n",
    "# then documents that will be closer to our query will have higher cosine similarity score \n",
    "# (cos(0) = 1 -> same direction of vectors). Vectorization gave us 2407 unique elements.\n",
    "doc_vectors[0:1]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cosine sim](https://cs.carleton.edu/cs_comps/0910/netflixprize/final_results/knn/img/knn/cos.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities[0]  # - this what happens when comparing same vectors with this metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>MagicalMysteryTour</td>\n",
       "      <td>All_You_Need_Is_Love.txt</td>\n",
       "      <td>Love, love, love Love, love, love Love, love, ...</td>\n",
       "      <td>0.694590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>AbbeyRoad</td>\n",
       "      <td>The_End.txt</td>\n",
       "      <td>Oh yeah All right Are you gonna be in my dream...</td>\n",
       "      <td>0.516073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>AbbeyRoad</td>\n",
       "      <td>Because.txt</td>\n",
       "      <td>Ah Because the world is round It turns me on B...</td>\n",
       "      <td>0.407631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>PleasePleaseMe</td>\n",
       "      <td>Love_Me_Do.txt</td>\n",
       "      <td>Love, love me do You know I love you I'll alwa...</td>\n",
       "      <td>0.392194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>Revolver</td>\n",
       "      <td>Tomorrow_Never_Knows.txt</td>\n",
       "      <td>Turn off your mind Relax and float down stream...</td>\n",
       "      <td>0.362012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 album                      song  \\\n",
       "73  MagicalMysteryTour  All_You_Need_Is_Love.txt   \n",
       "18           AbbeyRoad               The_End.txt   \n",
       "15           AbbeyRoad               Because.txt   \n",
       "42      PleasePleaseMe            Love_Me_Do.txt   \n",
       "59            Revolver  Tomorrow_Never_Knows.txt   \n",
       "\n",
       "                                                 text  similarity_score  \n",
       "73  Love, love, love Love, love, love Love, love, ...          0.694590  \n",
       "18  Oh yeah All right Are you gonna be in my dream...          0.516073  \n",
       "15  Ah Because the world is round It turns me on B...          0.407631  \n",
       "42  Love, love me do You know I love you I'll alwa...          0.392194  \n",
       "59  Turn off your mind Relax and float down stream...          0.362012  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_df = df.copy()\n",
    "top_df['similarity_score'] = document_scores\n",
    "top_df.sort_values('similarity_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1: tf-idf on preprocessed text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we will implement same algorithm on preprocessed text, results should be better, regarding the logic we'll get less sparsed matrix; cleaning stop-words, punctuation and lemmatization of our documents will result in lower quantity of elements in vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Love',\n",
       " ',',\n",
       " 'love',\n",
       " ',',\n",
       " 'mind',\n",
       " ')',\n",
       " 'Relax',\n",
       " '-',\n",
       " 'and',\n",
       " '(',\n",
       " 'float',\n",
       " 'down',\n",
       " 'stream',\n",
       " '...']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('Love, love, mind) Relax - and (float down stream...')  # results of word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "for word in 'all is love'.split():\n",
    "    if word in stop_words:\n",
    "        stop_words.remove(word)\n",
    "stop_words = set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "    ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`', '(', ')']\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t not in self.ignore_tokens]\n",
    "\n",
    "# Lemmatize the stop words\n",
    "tokenizer=LemmaTokenizer()\n",
    "token_stop = tokenizer(' '.join(stop_words))\n",
    "\n",
    "search_terms = 'all is love'\n",
    "documents = list(df.text)\n",
    "\n",
    "# Create TF-idf model\n",
    "vectorizer = TfidfVectorizer(stop_words=token_stop,\n",
    "                             tokenizer=tokenizer)\n",
    "doc_vectors = vectorizer.fit_transform([search_terms] + documents)\n",
    "\n",
    "# Calculate similarity\n",
    "cosine_similarities = linear_kernel(doc_vectors[0:1], doc_vectors).flatten()\n",
    "document_scores = [item.item() for item in cosine_similarities[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'love']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LemmaTokenizer()  # Example of how lemmatizer modifies words\n",
    "lm('cats loves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>MagicalMysteryTour</td>\n",
       "      <td>All_You_Need_Is_Love.txt</td>\n",
       "      <td>Love, love, love Love, love, love Love, love, ...</td>\n",
       "      <td>0.923018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>AbbeyRoad</td>\n",
       "      <td>The_End.txt</td>\n",
       "      <td>Oh yeah All right Are you gonna be in my dream...</td>\n",
       "      <td>0.734843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>PleasePleaseMe</td>\n",
       "      <td>Love_Me_Do.txt</td>\n",
       "      <td>Love, love me do You know I love you I'll alwa...</td>\n",
       "      <td>0.595745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>PleasePleaseMe</td>\n",
       "      <td>PS_I_Love_You.txt</td>\n",
       "      <td>As I write this letter Send my love to you Rem...</td>\n",
       "      <td>0.451099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>AHardDaysNight</td>\n",
       "      <td>And_I_Love_Her.txt</td>\n",
       "      <td>I give her all my love, that's all I do And if...</td>\n",
       "      <td>0.438177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 album                      song  \\\n",
       "73  MagicalMysteryTour  All_You_Need_Is_Love.txt   \n",
       "18           AbbeyRoad               The_End.txt   \n",
       "42      PleasePleaseMe            Love_Me_Do.txt   \n",
       "51      PleasePleaseMe         PS_I_Love_You.txt   \n",
       "12      AHardDaysNight        And_I_Love_Her.txt   \n",
       "\n",
       "                                                 text  similarity_score  \n",
       "73  Love, love, love Love, love, love Love, love, ...          0.923018  \n",
       "18  Oh yeah All right Are you gonna be in my dream...          0.734843  \n",
       "42  Love, love me do You know I love you I'll alwa...          0.595745  \n",
       "51  As I write this letter Send my love to you Rem...          0.451099  \n",
       "12  I give her all my love, that's all I do And if...          0.438177  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_df = df.copy()\n",
    "top_df['similarity_score'] = document_scores\n",
    "top_df.sort_values('similarity_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As one can see, with this approach, we get higher similarity scores. \"Love Me Do\" was on the 4th Place of previous ratings, now it's on the 3rd place. \"Because\" was dropped off top-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 3: Semantic Similarity with SoftCosineSimilarity metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectorize texts with respect to semantic similarity. \"cat\" is more similar to \"dog\" then to \"truck\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "for word in 'all is love'.split():\n",
    "    if word in stop_words:\n",
    "        stop_words.remove(word)\n",
    "stop_words = set(stop_words)\n",
    "\n",
    "def preprocess(doc):\n",
    "    return [token for token in simple_preprocess(doc, min_len=0, max_len=float(\"inf\")) if token not in stop_words]\n",
    "\n",
    "\n",
    "glove = api.load(\"glove-wiki-gigaword-50\")    \n",
    "similarity_index = WordEmbeddingSimilarityIndex(glove)\n",
    "\n",
    "search_terms = 'all is love'\n",
    "documents = list(df.text)\n",
    "\n",
    "corpus = [preprocess(document) for document in documents]\n",
    "query = preprocess(search_terms)\n",
    "\n",
    "dictionary = Dictionary(corpus+[query])\n",
    "tfidf = TfidfModel(dictionary=dictionary)\n",
    "\n",
    "similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nazariinyzhnyk/anaconda3/lib/python3.7/site-packages/gensim/similarities/termsim.py:358: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  Y = np.multiply(Y, 1 / np.sqrt(Y_norm))\n",
      "/Users/nazariinyzhnyk/anaconda3/lib/python3.7/site-packages/gensim/similarities/termsim.py:358: RuntimeWarning: invalid value encountered in multiply\n",
      "  Y = np.multiply(Y, 1 / np.sqrt(Y_norm))\n"
     ]
    }
   ],
   "source": [
    "query_tf = tfidf[dictionary.doc2bow(query)]\n",
    "\n",
    "index = SoftCosineSimilarity(\n",
    "            tfidf[[dictionary.doc2bow(document) for document in corpus]],\n",
    "            similarity_matrix)\n",
    "\n",
    "doc_similarity_scores = index[query_tf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>MagicalMysteryTour</td>\n",
       "      <td>All_You_Need_Is_Love.txt</td>\n",
       "      <td>Love, love, love Love, love, love Love, love, ...</td>\n",
       "      <td>0.987623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>MagicalMysteryTour</td>\n",
       "      <td>Penny_Lane.txt</td>\n",
       "      <td>In Penny Lane there is a barber showing photog...</td>\n",
       "      <td>0.981254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>SgtPeppers</td>\n",
       "      <td>Within_You_WIthout_You.txt</td>\n",
       "      <td>We were talking about the space between us all...</td>\n",
       "      <td>0.924626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>BeatlesForSale</td>\n",
       "      <td>Im_A_Loser.txt</td>\n",
       "      <td>I'm a loser I'm a loser And I'm not what I app...</td>\n",
       "      <td>0.916645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>Revolver</td>\n",
       "      <td>Love_You_To.txt</td>\n",
       "      <td>Each day just goes so fast I turn around, it's...</td>\n",
       "      <td>0.897382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  album                        song  \\\n",
       "73   MagicalMysteryTour    All_You_Need_Is_Love.txt   \n",
       "69   MagicalMysteryTour              Penny_Lane.txt   \n",
       "131          SgtPeppers  Within_You_WIthout_You.txt   \n",
       "78       BeatlesForSale              Im_A_Loser.txt   \n",
       "61             Revolver             Love_You_To.txt   \n",
       "\n",
       "                                                  text  similarity_score  \n",
       "73   Love, love, love Love, love, love Love, love, ...          0.987623  \n",
       "69   In Penny Lane there is a barber showing photog...          0.981254  \n",
       "131  We were talking about the space between us all...          0.924626  \n",
       "78   I'm a loser I'm a loser And I'm not what I app...          0.916645  \n",
       "61   Each day just goes so fast I turn around, it's...          0.897382  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_df = df.copy()\n",
    "top_df['similarity_score'] = doc_similarity_scores\n",
    "top_df.sort_values('similarity_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \"All_You_Need_Is_Love\" is still first, but places 2,3 now belong to Penny_Lane.txt, Within_You_WIthout_You.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 4: Semantic Similarity with distilbert and CosineSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "\n",
    "corpus = list(df.text)\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "query = 'all is love'\n",
    "\n",
    "query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "cos_scores = cos_scores.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>PleasePleaseMe</td>\n",
       "      <td>Love_Me_Do.txt</td>\n",
       "      <td>Love, love me do You know I love you I'll alwa...</td>\n",
       "      <td>0.722462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>PleasePleaseMe</td>\n",
       "      <td>PS_I_Love_You.txt</td>\n",
       "      <td>As I write this letter Send my love to you Rem...</td>\n",
       "      <td>0.675260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>AHardDaysNight</td>\n",
       "      <td>And_I_Love_Her.txt</td>\n",
       "      <td>I give her all my love, that's all I do And if...</td>\n",
       "      <td>0.671278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>AbbeyRoad</td>\n",
       "      <td>The_End.txt</td>\n",
       "      <td>Oh yeah All right Are you gonna be in my dream...</td>\n",
       "      <td>0.635978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>BeatlesForSale</td>\n",
       "      <td>Words_Of_Love.txt</td>\n",
       "      <td>Hold me close And tell me how you feel Tell me...</td>\n",
       "      <td>0.597593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             album                song  \\\n",
       "42  PleasePleaseMe      Love_Me_Do.txt   \n",
       "51  PleasePleaseMe   PS_I_Love_You.txt   \n",
       "12  AHardDaysNight  And_I_Love_Her.txt   \n",
       "18       AbbeyRoad         The_End.txt   \n",
       "85  BeatlesForSale   Words_Of_Love.txt   \n",
       "\n",
       "                                                 text  similarity_score  \n",
       "42  Love, love me do You know I love you I'll alwa...          0.722462  \n",
       "51  As I write this letter Send my love to you Rem...          0.675260  \n",
       "12  I give her all my love, that's all I do And if...          0.671278  \n",
       "18  Oh yeah All right Are you gonna be in my dream...          0.635978  \n",
       "85  Hold me close And tell me how you feel Tell me...          0.597593  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_df = df.copy()\n",
    "top_df['similarity_score'] = cos_scores.numpy()\n",
    "top_df.sort_values('similarity_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \"All_You_Need_Is_Love\" is not even in top-5! Probably \"all\" and \"is\" were removed from final corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's analyse top-3 songs, selected by algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf-idf selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Love, love, love Love, love, love Love, love, love  (Lo-o-ove) There's nothing you can do that can't be done (Lo-o-ove) Nothing you can sing that can't be sung (Lo-o-ove) Nothing you can say, but you can learn how to play the game It's easy  (Lo-o-ove) Nothing you can make that can't be made (Lo-o-ove) No-one you can save that can't be saved (Lo-o-ove) Nothing you can do, but you can learn how to be you in time It's easy  All you need is love All you need is love All you need is love, love Love is all you need  Lo-ove, love Love, love, love Love, love, love  All you need is love (Whoo) All you need is love (Hey) All you need is love, love Love is all you need  (Lo-o-ove) Nothing you can know that isn't known (Lo-o-ove) Nothing you can see that isn't shown (Lo-o-ove) There's nowhere you can be that isn't where you're meant to be It's easy  All you need is love All you need is love All you need is love, love Love is all you need  All you need is love (All together now!) All you need is love (Everybody!) All you need is love, love Love is all you need  Love is all you need (Love is all you need) Love is all you need (Love is all you need) Love is all you need (Love is all you need) Love is all you need (Love is all you need) Love is all you need (Love is all you need) Love is all you need (Love is all you need) Love is all you need (Love is all you need) Love is all you need (Love is all you need) Love is all you need (Love is all you need) Love is all you need (Love is all you need) Love is all you need (Yahoo!) (Love is all you need) Ye-hey! (Love is all) you need Love is all you need (Love is all you need) Yesterday (Love is all you need) Whoa Love is all you need Love is all you need Oh, yeah! Love is all you need Loves you, yeah, yeah, yeah (Love is all you need) (Love is all you need) She loves you, yeah, yeah, yeah (Love is all you need) (Love is all you need) (Love is all you need) Love is all you need (Love is) all you need (Love is all you need) Love is all you need Love is all you need (Love is all you need)\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[(df.song == \"All_You_Need_Is_Love.txt\")].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oh yeah All right Are you gonna be in my dreams Tonight?  Love you, love you, love you, love you Love you, love you, love you, love you Love you, love you, love you, love you Love you, love you, love you, love you Love you, love you, love you, love you Love you, love you, love you, love you  And in the end The love you take Is equal to the love you make']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[(df.song == \"The_End.txt\")].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ah Because the world is round It turns me on Because the world is round  Ah Because the wind is high It blows my mind Because the wind is high  Ah Love is old, love is new Love is all, love is you  Because the sky is blue It makes me cry Because the sky is blue']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[(df.song == \"Because.txt\")].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Love, love me do You know I love you I'll always be true So please, love me do Whoa, love me do  Love, love me do You know I love you I'll always be true So please, love me do Whoa, love me do  Someone to love Somebody new Someone to love Someone like you  Love, love me do You know I love you I'll always be true So please, love me do Whoa, love me do  Love, love me do You know I love you I'll always be true So please, love me do Whoa, love me do Yeah, love me do Whoa, love me do Yeah, love me do \"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[(df.song == \"Love_Me_Do.txt\")].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLOVE selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"In Penny Lane there is a barber showing photographs Of every head he's had the pleasure to know And all the people that come and go Stop and say hello  On the corner is a banker with a motorcar The little children laugh at him behind his back And the banker never wears a mac In the pouring rain Very strange  Penny Lane is in my ears and in my eyes There beneath the blue suburban skies I sit and meanwhile back  In Penny Lane, there is a fireman with an hour glass And in his pocket is a portrait of the Queen He likes to keep his fire engine clean It's a clean machine  Penny Lane is in my ears and in my eyes Four of fish and finger pies in summer Meanwhile back  Behind the shelter in the middle of the roundabout A pretty nurse is selling poppies from a tray And though she feels as if she's in a play She is anyway  In Penny Lane the barber shaves another customer We see the banker sitting waiting for a trim And then the fireman rushes in From the pouring rain Very strange  Penny Lane is in my ears and in my eyes There beneath the blue suburban skies I sit and meanwhile back  Penny Lane is in my ears and in my eyes There beneath the blue suburban skies Penny Lane\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[(df.song == \"Penny_Lane.txt\")].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"We were talking about the space between us all And the people who hide themselves behind a wall of illusion Never glimpse the truth Then it's far too late When they pass away  We were talking about the love we all could share when we find it To try our best to hold it there With our love With our love we could save the world If they only knew  Try to realize it's all within yourself No one else can make you change And to see you're really only very small And life flows on within you and without you  We were talking about the love that's gone so cold And the people who gain the world and lose their soul They don't know They can't see Are you one of them?  When you've seen beyond yourself Then you may find peace of mind is waiting there And the time will come when you see We're all one and life flows on within you and without you\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[(df.song == \"Within_You_WIthout_You.txt\")].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### distilBERT selections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I give her all my love, that's all I do And if you saw my love, you'd love her too I love her  She gives me everything and tenderly The kiss my lover brings, she brings to me And I love her  A love like ours could never die As long as I have you near me  Bright are the stars that shine, dark is the sky I know this love of mine will never die And I love her  Bright are the stars that shine, dark is the sky I know this love of mine will never die And I love her \"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[(df.song == \"And_I_Love_Her.txt\")].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"As I write this letter Send my love to you Remember that I'll always Be in love with you  Treasure these few words 'Til we're together Keep all my love forever P.S. I love you You, you, you  I'll be coming home again to you, love And 'til the day I do, love P.S. I love you You, you, you  As I write this letter Send my love to you Remember that I'll always Be in love with you  Treasure these few words 'Til we're together Keep all my love forever P.S. I love you You, you, you  As I write this letter Send my love to you (you know I want you to) Remember that I'll always Be in love with you  I'll be coming home again to you, love And 'til the day I do, love P.S. I love you You, you, you You, you, you I love you \"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[(df.song == \"PS_I_Love_You.txt\")].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I give her all my love, that's all I do And if you saw my love, you'd love her too I love her  She gives me everything and tenderly The kiss my lover brings, she brings to me And I love her  A love like ours could never die As long as I have you near me  Bright are the stars that shine, dark is the sky I know this love of mine will never die And I love her  Bright are the stars that shine, dark is the sky I know this love of mine will never die And I love her \"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[(df.song == \"And_I_Love_Her.txt\")].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What could be done next?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try other encoders, lemmatisation/stemming techniques, play with stopwords\n",
    "#### try other language models in sentence-transformers package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
